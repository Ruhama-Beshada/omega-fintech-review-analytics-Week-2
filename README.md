# 10 Academy â€“ AI Mastery Program  
## Week 2 Challenge: Customer Experience Analytics for Fintech Apps  

**Project:** Scraping, Analyzing, and Visualizing Google Play Store Reviews for Ethiopian Banks  
**Date:** 26 Nov â€“ 02 Dec 2025  

---

## ğŸ¯ Challenge Overview

This project simulates a real-world data engineering and analytics task. You act as a **Data Analyst at Omega Consultancy**, supporting three Ethiopian banks:

- Commercial Bank of Ethiopia (CBE)  
- Bank of Abyssinia (BOA)  
- Dashen Bank  

**Objective:** Scrape user reviews from Google Play, preprocess text, analyze sentiment and themes, visualize insights, and deliver actionable recommendations to improve mobile app performance and user satisfaction.

**Focus Areas:**  

- **User Retention:** Identify common complaints (e.g., slow transfers) and patterns in ratings.  
- **Feature Enhancement:** Extract desired features and improvement requests from reviews.  
- **Support Efficiency:** Cluster complaints to guide support strategies, including AI chatbot integration.  

---

## ğŸ—‚ Dataset Overview

- **Source:** Google Play Store  
- **Fields Collected:**  
  - `review_text` â†’ User feedback  
  - `rating` â†’ 1â€“5 stars  
  - `review_date` â†’ Date of review  
  - `bank_name` / `app_name` â†’ Bank identifier  
  - `source` â†’ Google Play  
- **Minimum Reviews:** 400 per bank (1,200 total)  

---

## ğŸš€ Project Tasks & Deliverables

### **Task 1: Data Collection & Preprocessing**
- **Web Scraping:** Use `google-play-scraper` or BeautifulSoup to collect reviews.  
- **Preprocessing:** Remove duplicates, normalize dates, clean text (remove emojis, URLs, stopwords).  
- **Deliverables:**  
  - Cleaned CSV with columns: `review`, `rating`, `date`, `bank`, `source`  
  - GitHub repo with organized commits in **task-1** branch  

**KPIs:** â‰¥1,200 reviews, <5% missing data, properly committed scripts  

---

### **Task 2: Sentiment & Thematic Analysis**
- **Sentiment Analysis:** Compute sentiment scores (positive/negative/neutral) using VADER, TextBlob, or a transformer model.  
- **Thematic Extraction:**  
  - Extract keywords (TF-IDF or regex-based)  
  - Cluster into 3â€“5 themes per bank (e.g., UI, Reliability, Customer Support)  
- **Deliverables:** CSV with `review_id`, `review_text`, `sentiment_label`, `sentiment_score`, `themes`  

**KPIs:** Sentiment scores for â‰¥90% of reviews, â‰¥3 themes per bank  

---

### **Task 3: Store Cleaned Data in PostgreSQL**
- **Database Setup:**  
  - Create `bank_reviews` database  
  - Tables: `banks` and `reviews` with proper keys and constraints  
- **Data Insertion:** Use Python (`psycopg2` or `SQLAlchemy`)  
- **Deliverables:** Working database with >1,000 reviews, schema documented in README  

---

### **Task 4: Insights & Recommendations**
- **Analysis:** Identify key drivers (e.g., speed) and pain points (e.g., crashes) per bank  
- **Visualization:** 3â€“5 plots (sentiment trends, rating distributions, keyword clouds)  
- **Recommendations:** Actionable improvements per bank  

**KPIs:** â‰¥2 drivers/pain points per bank, stakeholder-ready visualizations  

---

## ğŸ“‚ Project Structure

omega-fintech-review-analytics-Week-2/
â”‚
â”œâ”€â”€ Scripts/
â”‚ â”œâ”€â”€ task1_scraper.py
â”‚ â”œâ”€â”€ task1_cleaner.py
â”‚ â””â”€â”€ task2_sentiment_thematic.py
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ task1_scraping_cleaning.ipynb
â”‚ â”œâ”€â”€ task2_analysis.ipynb
â”‚ â””â”€â”€ data/
â”‚ â”œâ”€â”€ raw/reviews_raw.csv
â”‚ â””â”€â”€ processed/reviews_clean.csv
â”‚
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ Interim_Report.pdf
â”‚ â””â”€â”€ Final_Report.pdf
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸ›  How to Run the Project

1ï¸âƒ£ **Setup virtual environment**

```bash
python -m venv .venv
# Activate
# Mac/Linux
source .venv/bin/activate
# Windows
.\.venv\Scripts\activate


2ï¸âƒ£ Install dependencies

pip install -r requirements.txt


3ï¸âƒ£ Run Task 1 scripts

python Scripts/task1_scraper.py
python Scripts/task1_cleaner.py


4ï¸âƒ£ Run Task 2 analysis

python Scripts/task2_sentiment_thematic.py


Or use the Jupyter notebooks in /notebooks.


